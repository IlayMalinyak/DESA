Data:
  # Basics
  log_dir: '/data/lightSpec/logs'
  exp_num: 1
  light_model_name: "MultiTaskRegressor"
  spec_model_name: "MultiTaskRegressor"
  combined_model_name: "MultiEncoder"
  # Data
  dataset: "LightSpecDataset"
  data_dir: '/data/lightPred/data'
  spectra_dir: '/data/lamost/data'
  batch_size: 4
  num_epochs: 1000
  max_len_spectra: 4096
  max_days_lc: 540
  max_len_lc: 26112
  lc_freq: 0.0208
  continuum_norm: True
  meta_columns: ['Teff', 'Mstar']
  labels: ['Teff', 'logg', 'FeH', 'Rstar', 'RUWE']
  test_run: False
  create_umap: False
  load_checkpoint: False
  masked_transform: False
  use_acf: True
  scale_flux: False
  combined_embed: False
  pred_coeff_val: None
  approach: "multitask"
  checkpoint_path: '/data/lightSpec/logs/lightspec_2025-02-24/lightspec_2.pth'

Astroconformer:
  # Model
  in_channels: 1
  encoder: ["mhsa_pro", "conv", "mhsa_pro"]
  decoder: ["mhsa_decoder",  "conv", "mhsa_decoder"]
  timeshift: false
  num_layers: 8
  num_decoder_layers: 12
  stride: 2
  encoder_dim: 128
  decoder_dim: 512
  num_heads: 4
  kernel_size: 3
  dropout_p: 0.3
  output_dim: 3
  norm: "postnorm"
  beta: 1
  load_light_checkpoint: True
  light_checkpoint_path: '/data/lightSpec/logs/exp5/astroconf_lc_1.pth'

AstroEncoderDecoder:
  # Model
  in_channels: 1
  encoder: ["mhsa_pro", "conv", "mhsa_pro"]
  decoder: ["mhsa_decoder",  "conv", "mhsa_decoder"]
  timeshift: false
  num_layers: 6
  num_decoder_layers: 6
  stride: 2
  encoder_dim: 512
  decoder_dim: 512
  num_heads: 4
  kernel_size: 3
  dropout_p: 0.2
  output_dim: 3
  norm: "postnorm"
  load_spec_checkpoint: False
  spec_checkpoint_path: '/data/lightSpec/logs/exp6/astroconf_spectra_3.pth'

MultiEncoder_lc:
  # Model
  in_channels: 2
  num_layers: 8
  stride: 1
  encoder_dims: [32,64,128,256,512,2048]
  kernel_size: 3
  dropout_p: 0.3
  output_dim: 2
  beta: 1
  avg_output: True
  load_checkpoint: True
  checkpoint_num: 1
  activation: "sine"
  sine_w0: 1.0
  checkpoint_path: '/data/lightSpec/logs/light_2025-02-11/MultiEncoder_lc_1.pth'


Conformer_lc:
  encoder: ["mhsa_pro", "conv", "ffn"]
  timeshift: false
  num_layers: 6
  stride: 2
  encoder_dim: 2048
  num_heads: 8
  kernel_size: 3
  dropout_p: 0.2
  norm: "shortcut"

MultiTaskRegressor_lc:
  in_channels: 2
  num_layers: 5
  stride: 1
  encoder_dims: [64,128,256,1024,2048]
  transformer_layers: 4
  kernel_size: 3
  dropout_p: 0.2
  avg_output: True
  output_dim: 2
  num_quantiles: 5
  beta: 1
  load_checkpoint: True
  checkpoint_num: 1
  activation: "sine"
  sine_w0: 1.0
  checkpoint_path: "/data/lightSpec/logs/light_2025-03-01/MultiTaskRegressor_lc_2.pth"



MultiTaskRegressor_spec:
  in_channels: 1
  num_layers: 5
  stride: 1
  encoder_dims: [64,128,256,1024,2048]
  transformer_layers: 4
  kernel_size: 3
  dropout_p: 0.2
  avg_output: True
  output_dim: 3
  num_quantiles: 5
  beta: 1
  load_checkpoint: True
  checkpoint_num: 1
  activation: "silu"
  checkpoint_path: "/data/lightSpec/logs/spec_decode2_2025-02-16/MultiTaskRegressor_spectra_decode_4.pth"


Conformer_spec:
  encoder: ["mhsa_pro", "conv", "ffn"]
  timeshift: false
  num_layers: 8
  encoder_dim: 2048
  num_heads: 8
  kernel_size: 3
  dropout_p: 0.2
  norm: "postnorm"


MultiEncoder_combined:
  # Model
  in_channels: 3
  num_layers: 8
  stride: 1
  encoder_dims: [32,64,128,256,512,2048]
  kernel_size: 3
  dropout_p: 0.3
  output_dim: 2
  beta: 1
  avg_output: True
  load_checkpoint: True
  checkpoint_num: 1
  activation: "sine"
  sine_w0: 1.0
  checkpoint_path: '/data/lightSpec/logs/combined_2025-02-12/lightspec_1.pth'


Conformer_combined:
  encoder: ["mhsa_pro", "conv", "ffn"]
  timeshift: false
  num_layers: 6
  stride: 2
  encoder_dim: 2048
  num_heads: 8
  kernel_size: 3
  dropout_p: 0.2
  norm: "shortcut"

MultiEncoder_lightspec:
  # Model
  in_channels: 1
  num_layers: 6
  stride: 1
  encoder_dims: [32,64,128,256,512]
  kernel_size: 3
  dropout_p: 0.3
  output_dim: 2
  beta: 1
  load_checkpoint: False
  checkpoint_num: 1
  activation: "sine"
  sine_w0: 1.0
  avg_output: True
  checkpoint_path: ''

Conformer_lightspec:
  encoder: ["mhsa_pro", "conv", "ffn"]
  timeshift: false
  num_layers: 8
  encoder_dim: 512
  num_heads: 8
  kernel_size: 3
  dropout_p: 0.2
  norm: "postnorm"

Transformer_lightspec:
  in_channels: 1
  num_layers: 4
  encoder_dim: 256
  dropout_p: 0.2
  num_heads: 8
  dropout: 0.0
  output_dim: 64
  num_quantiles: 1
  checkpoint_num: 1
  load_checkpoint: False


Conformer_lightspec:
  encoder: ["mhsa_pro", "conv", "ffn"]
  timeshift: false
  num_layers: 4
  stride: 2
  encoder_dim: 256
  num_heads: 8
  kernel_size: 3
  dropout_p: 0.2
  norm: "shortcut"

CNNEncoder:
  # Model
  in_channels: 1
  num_layers: 8
  stride: 1
  encoder_dims: [32,64,128,256,512]
  kernel_size: 3
  dropout_p: 0.2
  output_dim: 2
  beta: 1
  load_checkpoint: True
  avg_output: True
  checkpoint_num: 2
  activation: "sine"
  sine_w0: 1.0
  load_checkpoint: True
  checkpoint_path: '/data/lightSpec/logs/light_2024-11-27/CNNEncoder_lc_1.pth'

CNNEncoderDecoder_lc:
  # Model
  in_channels: 1
  num_layers: 8
  stride: 1
  encoder_dims: [32,64,128,256,512]
  kernel_size: 3
  dropout_p: 0.3
  output_dim: 2
  beta: 1
  load_checkpoint: True
  checkpoint_num: 1
  activation: "sine"
  sine_w0: 1.0
  avg_output: True
  checkpoint_path: '/data/lightSpec/logs/light_2025-02-04/CNNEncoderDecoder_lc_2.pth'

MoCo:
  # Model
  K: 4096
  m: 0.9
  T: 0.05
  hidden_dim: 512
  projection_dim: 512
  num_layers: 6
  freeze_lightcurve: False
  freeze_spectra: False
  freeze_combined: False
  bidirectional: True

predictor:
  in_dim: 64
  hidden_dim: 256
  out_dim: 64
  w_dim: 2


reg_predictor:
  in_dim: 128
  hidden_dim: 512
  out_dim: 20
  w_dim: 0


loss:
  sim_coeff: 25
  std_coeff: 25 
  cov_coeff: 1

MultiModalSimSiam:
  # Model
  input_dim: 512
  hidden_dim: 64
  projection_dim: 32
  output_dim: 32
  dropout: 0.2
  freeze_backbone: True

CNNBackbone:
  # Model
  in_channels: 1
  num_layers: 8
  stride: 1
  encoder_dims: [64,128,256,512]
  kernel_size: 3
  dropout_p: 0.3
  beta: 1
  avg_output: True
  activation: "silu"
  sine_w0: 1.0
  load_checkpoint: False

conv_args:
  in_channels: 1
  num_layers: 8
  stride: 1
  encoder_dims: [64,128,256,512]
  kernel_size: 3
  dropout_p: 0.3
  beta: 1
  avg_output: True
  activation: "silu"
  
Optimization:
  # Optimization
  max_lr:  5e-5
  weight_decay: 1e-6
  warmup_pct: 0.15
  steps_per_epoch: 3500
  momentum: 0.95
  nesterov: true
  optimizer: "adamw"
  quantiles: [0.1, 0.25, 0.5, 0.75, 0.9]

